{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Corpus Export\n",
    "\n",
    "Select documents from large imported set and merge with an annotated document collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "%run env.py\n",
    "%run src/integration.py\n",
    "article_data_file = osp.join(DATA_DIR, 'articles', 'data.csv')\n",
    "corpus_dir = osp.join(DATA_DIR, 'articles', 'corpus', 'corpus_00', 'docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 6 columns):\n",
      "abstract    3481 non-null object\n",
      "date        2155 non-null object\n",
      "has_text    3500 non-null bool\n",
      "id          3500 non-null int64\n",
      "title       3500 non-null object\n",
      "xml         3500 non-null object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 140.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(article_data_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 500 entries, 1322 to 749\n",
      "Data columns (total 6 columns):\n",
      "abstract    499 non-null object\n",
      "date        308 non-null object\n",
      "has_text    500 non-null bool\n",
      "id          500 non-null int64\n",
      "title       500 non-null object\n",
      "xml         500 non-null object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 23.9+ KB\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 500\n",
    "df = df.sample(n=LIMIT, random_state=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:22<00:00, 21.85it/s]\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "for i, r in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    body = extract_text(r['xml'])\n",
    "    text.append(combine_text(r['title'], r['abstract'], body))\n",
    "df['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:00, 2361.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/eczech/data/research/hammer/nlp/20190311-pubmed-tcell-relation/articles/corpus/corpus_00/docs'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export un-annotated documents\n",
    "if not osp.exists(corpus_dir):\n",
    "    os.makedirs(corpus_dir)\n",
    "\n",
    "for i, r in tqdm.tqdm(df.iterrows()):\n",
    "    path = osp.join(corpus_dir, 'PMC{}.txt'.format(r['id']))\n",
    "    with open(path, 'w') as fd:\n",
    "        fd.write(r['text'])\n",
    "corpus_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
