{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snorkel\n",
    "import dotenv\n",
    "from snorkel.parser import TextDocPreprocessor\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "dotenv.load_dotenv('../env.sh')\n",
    "%run ../src/supervision.py\n",
    "corpus_dir = osp.join(os.environ['DATA_DIR'], 'articles', 'corpus', 'corpus_00')\n",
    "corpus_docs_dir = osp.join(corpus_dir, 'links')\n",
    "collection_dir = osp.join(os.environ['REPO_DATA_DIR'], 'brat', 'collection_02')\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear existing candidates, if need be\n",
    "\n",
    "from snorkel.models import Candidate\n",
    "ct = session.query(Candidate).count()\n",
    "# if ct > 0:\n",
    "#     # Clear all existing candidates (don't let extractors do it)\n",
    "#     # See: https://github.com/HazyResearch/snorkel/blob/master/snorkel/candidates.py#L47\n",
    "#     # *This seems to always cause a database lock somehow -- perhaps it needs to be done with autocommit but\n",
    "#     # for now a workaround is to do this at the beginning and the restart the kernel\n",
    "#     from snorkel.models import Candidate\n",
    "#     ndelete = session.query(Candidate).delete()\n",
    "#     session.commit()\n",
    "#     # Restart kernel\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYTOKINE                22425\n",
      "IMMUNE_CELL_TYPE        20807\n",
      "TRANSCRIPTION_FACTOR    16721\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>ent_id</th>\n",
       "      <th>ent_lbl</th>\n",
       "      <th>ent_prefid</th>\n",
       "      <th>start_chr</th>\n",
       "      <th>end_chr</th>\n",
       "      <th>start_wrd</th>\n",
       "      <th>end_wrd</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC5743442</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>CTBFBDE5121B6748D1</td>\n",
       "      <td>Th17</td>\n",
       "      <td>CTBFBDE5121B6748D1</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Th17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC5743442</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>CTBFBDE5121B6748D1</td>\n",
       "      <td>Th17</td>\n",
       "      <td>CTBFBDE5121B6748D1</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Th17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC5743442</td>\n",
       "      <td>CYTOKINE</td>\n",
       "      <td>CKFD4CA0B2B4BC3AE4</td>\n",
       "      <td>TGF-β</td>\n",
       "      <td>CKFD4CA0B2B4BC3AE4</td>\n",
       "      <td>174</td>\n",
       "      <td>179</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>TGF-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC5743442</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>CTBFBDE5121B6748D1</td>\n",
       "      <td>Th17</td>\n",
       "      <td>CTBFBDE5121B6748D1</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>Th17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PMC5743442</td>\n",
       "      <td>CYTOKINE</td>\n",
       "      <td>CKC59F8990F767EBD4</td>\n",
       "      <td>TGF-β</td>\n",
       "      <td>CKFD4CA0B2B4BC3AE4</td>\n",
       "      <td>275</td>\n",
       "      <td>280</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>TGF-β</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id              type              ent_id ent_lbl  \\\n",
       "1  PMC5743442  IMMUNE_CELL_TYPE  CTBFBDE5121B6748D1    Th17   \n",
       "2  PMC5743442  IMMUNE_CELL_TYPE  CTBFBDE5121B6748D1    Th17   \n",
       "3  PMC5743442          CYTOKINE  CKFD4CA0B2B4BC3AE4   TGF-β   \n",
       "4  PMC5743442  IMMUNE_CELL_TYPE  CTBFBDE5121B6748D1    Th17   \n",
       "6  PMC5743442          CYTOKINE  CKC59F8990F767EBD4   TGF-β   \n",
       "\n",
       "           ent_prefid  start_chr  end_chr  start_wrd  end_wrd   text  \n",
       "1  CTBFBDE5121B6748D1         65       69          8        9   Th17  \n",
       "2  CTBFBDE5121B6748D1         87       91         11       12   Th17  \n",
       "3  CKFD4CA0B2B4BC3AE4        174      179         25       26  TGF-β  \n",
       "4  CTBFBDE5121B6748D1        199      203         29       30   Th17  \n",
       "6  CKFD4CA0B2B4BC3AE4        275      280         42       43  TGF-β  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pd.read_csv(osp.join(corpus_dir, 'tags.csv'))\n",
    "tags = tags[tags['type'].isin(ENT_TYPES)]\n",
    "print(tags['type'].value_counts())\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_preprocessor = TextDocPreprocessor(corpus_docs_dir, max_docs=10)\n",
    "doc_preprocessor = TextDocPreprocessor(corpus_docs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     62\n",
       "False     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_annotated_doc_ids():\n",
    "    import glob\n",
    "    return [osp.splitext(osp.basename(f))[0] for f in glob.glob(osp.join(collection_dir, '*.txt'))]\n",
    "annotated_ids = get_annotated_doc_ids()\n",
    "# Show frequency of docs that are annotated AND have tags of some kind\n",
    "pd.Series({did:did in tags['id'].values for did in annotated_ids}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def offsets_to_token(left, right, offset_array, lemmas, punc=set(punctuation)):\n",
    "    token_start, token_end = None, None\n",
    "    for i, c in enumerate(offset_array):\n",
    "        if left >= c:\n",
    "            token_start = i\n",
    "        if c > right and token_end is None:\n",
    "            token_end = i\n",
    "            break\n",
    "    token_end = len(offset_array) - 1 if token_end is None else token_end\n",
    "    token_end = token_end - 1 if lemmas[token_end - 1] in punc else token_end\n",
    "    return range(token_start, token_end)\n",
    "\n",
    "\n",
    "class EntityTagger(object):\n",
    "\n",
    "    def __init__(self, tags):   \n",
    "        self.tags = tags.set_index('id')\n",
    "        self.reset_stats()\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.stats = {'docs': set(), 'found': set()}\n",
    "        return self\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return dict(\n",
    "            n_tags=len(self.tags), \n",
    "            n_docs=len(self.stats['docs']),\n",
    "            n_docs_found=len(self.stats['found']),\n",
    "            pct_docs_found=100*len(self.stats['found'])/len(self.stats['docs'])\n",
    "        )\n",
    "    \n",
    "    def tag(self, parts):\n",
    "        \"\"\"Tag tokens in a single sentence\"\"\"\n",
    "        # Extract doc id (e.g. PMC123932) and character offsets of sentence\n",
    "        docid, _, _, sent_start, sent_end = parts['stable_id'].split(':')\n",
    "        self.stats['docs'].add(docid)\n",
    "        if docid not in self.tags.index:\n",
    "            return parts\n",
    "        self.stats['found'].add(docid)\n",
    "        tags = self.tags.loc[[docid]]\n",
    "        sent_start, sent_end = int(sent_start), int(sent_end)\n",
    "        for r in tags.itertuples():\n",
    "            tag_start, tag_end = r.start_chr, r.end_chr\n",
    "            # Determine whether or not the tag is in this sentence\n",
    "            if not (sent_start <= tag_start <= sent_end):\n",
    "                continue\n",
    "            offsets = [offset + sent_start for offset in parts['char_offsets']]\n",
    "            tkn_idx_rng = offsets_to_token(tag_start, tag_end, offsets, parts['lemmas'])\n",
    "            for tkn_idx in tkn_idx_rng:\n",
    "                parts['entity_types'][tkn_idx] = r.type.lower()\n",
    "                parts['entity_cids'][tkn_idx] = r.ent_id + ':' + r.ent_prefid\n",
    "        return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/555 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 555/555 [06:33<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser, Spacy\n",
    "\n",
    "tagger = EntityTagger(tags)\n",
    "corpus_parser = CorpusParser(fn=tagger.tag)\n",
    "corpus_parser.apply(list(doc_preprocessor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_tags': 59953,\n",
       " 'n_docs': 555,\n",
       " 'n_docs_found': 520,\n",
       " 'pct_docs_found': 93.69369369369369}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will show how many documents didn't have any tagged\n",
    "# (or that were otherwise not included in tagging but included\n",
    "# here in parsing -- which should be rare)\n",
    "tagger.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 555\n",
      "Sentences: 72223\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = session.query(Document).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 65)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = [doc.name for doc in docs]\n",
    "tagged_ids = list(np.intersect1d(all_ids, tags['id']))\n",
    "dev_ids = list(set(annotated_ids))\n",
    "train_ids = [i for i in tagged_ids if i not in dev_ids]\n",
    "len(train_ids), len(dev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents, dev_sents = set(), set()\n",
    "for i, doc in enumerate(docs):\n",
    "    if doc.name not in tagged_ids:\n",
    "        continue\n",
    "    for s in doc.sentences:\n",
    "        if doc.name in train_ids:\n",
    "            train_sents.add(s)\n",
    "        elif doc.name in dev_ids:\n",
    "            dev_sents.add(s)\n",
    "        else:\n",
    "            raise Exception('ID <{0}> not found in any id set'.format(doc.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "classes = get_candidate_classes()\n",
    "candidate_extractors = [\n",
    "    PretaggedCandidateExtractor(c.subclass, c.entity_types)\n",
    "    for c in classes.values()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 141/70540 [00:00<00:50, 1400.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70540/70540 [00:41<00:00, 1715.93it/s]\n",
      "  0%|          | 315/70540 [00:00<00:22, 3149.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates generated for split 0, relation type InducingCytokine: 11836\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70540/70540 [00:26<00:00, 2652.90it/s]\n",
      "  0%|          | 213/70540 [00:00<00:33, 2100.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates generated for split 0, relation type SecretedCytokine: 11836\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70540/70540 [00:27<00:00, 2564.78it/s]\n",
      "  4%|▍         | 61/1449 [00:00<00:02, 598.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates generated for split 0, relation type InducingTranscriptionFactor: 8477\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1449/1449 [00:01<00:00, 1169.34it/s]\n",
      "  4%|▎         | 54/1449 [00:00<00:03, 360.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates generated for split 1, relation type InducingCytokine: 593\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1449/1449 [00:01<00:00, 1342.74it/s]\n",
      "  8%|▊         | 113/1449 [00:00<00:01, 1109.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates generated for split 1, relation type SecretedCytokine: 593\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1449/1449 [00:01<00:00, 1404.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates generated for split 1, relation type InducingTranscriptionFactor: 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k, sents in enumerate([train_sents, dev_sents]):\n",
    "    for extractor in candidate_extractors:\n",
    "        relation_class = extractor.udf_init_kwargs['candidate_class']\n",
    "        extractor.apply(sents, split=k, clear=False)\n",
    "        print('Number of candidates generated for split {}, relation type {}: {}'.format(\n",
    "            k, relation_class.__name__,\n",
    "            session.query(relation_class).filter(relation_class.split == k).count()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e1_end_chr</th>\n",
       "      <th>e1_start_chr</th>\n",
       "      <th>e1_text</th>\n",
       "      <th>e1_typ</th>\n",
       "      <th>e2_end_chr</th>\n",
       "      <th>e2_start_chr</th>\n",
       "      <th>e2_text</th>\n",
       "      <th>e2_typ</th>\n",
       "      <th>id</th>\n",
       "      <th>rel_typ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>Gfi-1</td>\n",
       "      <td>TRANSCRIPTION_FACTOR</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>Th17</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>PMC2646571</td>\n",
       "      <td>Differentiation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>TGF-β</td>\n",
       "      <td>CYTOKINE</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>Th17</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>PMC2646571</td>\n",
       "      <td>Induction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>TGF-β</td>\n",
       "      <td>CYTOKINE</td>\n",
       "      <td>125</td>\n",
       "      <td>90</td>\n",
       "      <td>CD103+ inducible regulatory T cells</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>PMC2646571</td>\n",
       "      <td>Induction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>Gfi-1</td>\n",
       "      <td>TRANSCRIPTION_FACTOR</td>\n",
       "      <td>125</td>\n",
       "      <td>90</td>\n",
       "      <td>CD103+ inducible regulatory T cells</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>PMC2646571</td>\n",
       "      <td>Differentiation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371</td>\n",
       "      <td>366</td>\n",
       "      <td>Gfi-1</td>\n",
       "      <td>TRANSCRIPTION_FACTOR</td>\n",
       "      <td>436</td>\n",
       "      <td>433</td>\n",
       "      <td>Th2</td>\n",
       "      <td>IMMUNE_CELL_TYPE</td>\n",
       "      <td>PMC2646571</td>\n",
       "      <td>Differentiation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e1_end_chr  e1_start_chr e1_text                e1_typ  e2_end_chr  \\\n",
       "0          24            19   Gfi-1  TRANSCRIPTION_FACTOR          85   \n",
       "1          44            39   TGF-β              CYTOKINE          85   \n",
       "2          44            39   TGF-β              CYTOKINE         125   \n",
       "3          24            19   Gfi-1  TRANSCRIPTION_FACTOR         125   \n",
       "4         371           366   Gfi-1  TRANSCRIPTION_FACTOR         436   \n",
       "\n",
       "   e2_start_chr                              e2_text            e2_typ  \\\n",
       "0            81                                 Th17  IMMUNE_CELL_TYPE   \n",
       "1            81                                 Th17  IMMUNE_CELL_TYPE   \n",
       "2            90  CD103+ inducible regulatory T cells  IMMUNE_CELL_TYPE   \n",
       "3            90  CD103+ inducible regulatory T cells  IMMUNE_CELL_TYPE   \n",
       "4           433                                  Th2  IMMUNE_CELL_TYPE   \n",
       "\n",
       "           id          rel_typ  \n",
       "0  PMC2646571  Differentiation  \n",
       "1  PMC2646571        Induction  \n",
       "2  PMC2646571        Induction  \n",
       "3  PMC2646571  Differentiation  \n",
       "4  PMC2646571  Differentiation  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv export with annotated relations to load:\n",
    "relations = pd.read_csv(osp.join(corpus_dir, 'relations.csv'))\n",
    "relations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Induction          129\n",
       "Secretion          113\n",
       "Differentiation    101\n",
       "Name: rel_typ, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations['rel_typ'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e1_typ                e2_typ            rel_typ        \n",
       "CYTOKINE              IMMUNE_CELL_TYPE  Induction          129\n",
       "                                        Secretion          113\n",
       "TRANSCRIPTION_FACTOR  IMMUNE_CELL_TYPE  Differentiation    101\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations.groupby(['e1_typ', 'e2_typ', 'rel_typ']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset annotation tables (if loading them below fails)\n",
    "# session.execute('DELETE FROM stable_label;')\n",
    "# session.execute('DELETE FROM gold_label;')\n",
    "# session.execute('DELETE FROM gold_label_key;')\n",
    "# from snorkel.models import GoldLabel, GoldLabelKey, StableLabel\n",
    "# session.commit()\n",
    "# session.query(StableLabel).count(), session.query(GoldLabel).count(), session.query(GoldLabelKey).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129 relations for type Induction\n",
      "inducing_cytokine\n",
      "AnnotatorLabels created: 112, missed: 17\n",
      "Found 113 relations for type Secretion\n",
      "secreted_cytokine\n",
      "AnnotatorLabels created: 65, missed: 48\n",
      "Found 101 relations for type Differentiation\n",
      "inducing_transcription_factor\n",
      "AnnotatorLabels created: 59, missed: 42\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import StableLabel\n",
    "from snorkel.db_helpers import reload_annotator_labels\n",
    "\n",
    "def get_stable_id(r):\n",
    "    return '{}::span:{}:{}'.format(r['id'], r['start_chr'], r['end_chr']-1)\n",
    "\n",
    "def reload_labels(\n",
    "    session, candidate_class, annotator_name, split, \n",
    "    filter_label_split=True, create_missing_cands=False):\n",
    "    \"\"\"Reloads stable annotator labels into the AnnotatorLabel table\"\"\"\n",
    "    from snorkel.models import GoldLabel, GoldLabelKey, StableLabel, Context\n",
    "    from future.utils import iteritems\n",
    "    # Sets up the AnnotatorLabelKey to use\n",
    "    ak = session.query(GoldLabelKey).filter(GoldLabelKey.name == annotator_name).first()\n",
    "    if ak is None:\n",
    "        ak = GoldLabelKey(name=annotator_name)\n",
    "        session.add(ak)\n",
    "        session.commit()\n",
    "\n",
    "    labels = []\n",
    "    missed = []\n",
    "    sl_query = session.query(StableLabel).filter(StableLabel.annotator_name == annotator_name)\n",
    "    sl_query = sl_query.filter(StableLabel.split == split) if filter_label_split else sl_query\n",
    "    for sl in sl_query.all():\n",
    "        context_stable_ids = sl.context_stable_ids.split('~~')\n",
    "\n",
    "        # Check for labeled Contexts\n",
    "        # TODO: Does not create the Contexts if they do not yet exist!\n",
    "        contexts = []\n",
    "        for stable_id in context_stable_ids:\n",
    "            context = session.query(Context).filter(Context.stable_id == stable_id).first()\n",
    "            if context:\n",
    "                contexts.append(context)\n",
    "        if len(contexts) < len(context_stable_ids):\n",
    "            missed.append(sl)\n",
    "            continue\n",
    "\n",
    "        # Check for Candidate\n",
    "        # Assemble candidate arguments\n",
    "        candidate_args  = {'split' : split}\n",
    "        for i, arg_name in enumerate(candidate_class.__argnames__):\n",
    "            candidate_args[arg_name] = contexts[i]\n",
    "\n",
    "        # Assemble query and check\n",
    "        candidate_query = session.query(candidate_class)\n",
    "        for k, v in iteritems(candidate_args):\n",
    "            candidate_query = candidate_query.filter(getattr(candidate_class, k) == v)\n",
    "        candidate = candidate_query.first()\n",
    "\n",
    "        # Optionally construct missing candidates\n",
    "        if candidate is None and create_missing_cands:\n",
    "            candidate = candidate_class(**candidate_args)\n",
    "\n",
    "        # If candidate is none, mark as missed and continue\n",
    "        if candidate is None:\n",
    "            missed.append(sl)\n",
    "            continue\n",
    "\n",
    "        # Check for AnnotatorLabel, otherwise create\n",
    "        label = session.query(GoldLabel).filter(GoldLabel.key == ak).filter(GoldLabel.candidate == candidate).first()\n",
    "        if label is None:\n",
    "            label = GoldLabel(candidate=candidate, key=ak, value=sl.value)\n",
    "            session.add(label)\n",
    "            labels.append(label)\n",
    "\n",
    "    session.commit()\n",
    "    print(\"AnnotatorLabels created: %s, missed: %s\" % (len(labels), len(missed)))\n",
    "    return missed, labels\n",
    "    \n",
    "def load_external_labels(session, relations, candidate_class, annotator_name='gold'):\n",
    "    print(annotator_name)\n",
    "    for i, r in relations.iterrows():    \n",
    "\n",
    "        # We check if the label already exists, in case this cell was already executed\n",
    "        e1_id = get_stable_id(r.filter(regex='^e1_|^id$').rename(lambda v: v.replace('e1_', '')))\n",
    "        e2_id = get_stable_id(r.filter(regex='^e2_|^id$').rename(lambda v: v.replace('e2_', '')))\n",
    "        \n",
    "        context_stable_ids = \"~~\".join([e1_id, e2_id])\n",
    "        query = session.query(StableLabel)\\\n",
    "            .filter(StableLabel.context_stable_ids == context_stable_ids)\\\n",
    "            .filter(StableLabel.annotator_name == annotator_name)\n",
    "        if query.count() == 0:\n",
    "            session.add(StableLabel(\n",
    "                context_stable_ids=context_stable_ids,\n",
    "                annotator_name=annotator_name,\n",
    "                value=1\n",
    "            ))\n",
    "            \n",
    "    session.commit()\n",
    "    # This function will create GoldLabel records for each StableLabel above after\n",
    "    # selecting them based on annotator_name.  The annotator name should be different\n",
    "    # for each candidate class if they might have identical context_stable_ids since\n",
    "    # otherwise as written above only the first value for the same annotator + context_stable_ids\n",
    "    # will be saved.\n",
    "    # Other notes: split will be used to find candidates necessary to create GoldLabels though\n",
    "    # it is not necessary for StableLabel filtering in this case (thus filter_label_split=False)\n",
    "    # because the labels were not created with a split above\n",
    "    #reload_annotator_labels(\n",
    "    return reload_labels(\n",
    "        session, candidate_class, annotator_name, split=1, \n",
    "        filter_label_split=False, create_missing_cands=False)\n",
    "    \n",
    "cand_summary = {}\n",
    "for extractor in candidate_extractors:\n",
    "    relation_class = extractor.udf_init_kwargs['candidate_class']\n",
    "    label = classes[relation_class.__name__].label\n",
    "    field = classes[relation_class.__name__].field\n",
    "    df = relations[relations['rel_typ'] == label]\n",
    "    assert len(df) > 0, 'Found no records for relation type {}'.format(label)\n",
    "    print('Found {} relations for type {}'.format(len(df), label))\n",
    "    cand_summary[relation_class.__name__] = load_external_labels(session, df, relation_class, annotator_name=field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relation                     missing                              \n",
       "InducingCytokine             cytokine                                  4\n",
       "                             cytokine,immune_cell_type                 1\n",
       "                             immune_cell_type                         12\n",
       "InducingTranscriptionFactor                                            1\n",
       "                             immune_cell_type                          5\n",
       "                             transcription_factor                     28\n",
       "                             transcription_factor,immune_cell_type     8\n",
       "SecretedCytokine             cytokine                                  9\n",
       "                             cytokine,immune_cell_type                 3\n",
       "                             immune_cell_type                         36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.models import Context \n",
    "\n",
    "# Show which entity types and relations were unable to be matched with spans\n",
    "# extracted and inserted into snorkel db\n",
    "def summarize_missing_candidates(cand_summary):\n",
    "    df = []\n",
    "    for c in cand_summary:\n",
    "        class_name = classes[c].name\n",
    "        missed = cand_summary[c][0]\n",
    "        for mc in missed:\n",
    "            doc_id = mc.context_stable_ids.split('::')[0]\n",
    "            ids = mc.context_stable_ids.split('~~')\n",
    "            typs = []\n",
    "            for i, sid in enumerate(ids):\n",
    "                ctx = session.query(Context).filter(Context.stable_id == sid).all()\n",
    "                if len(ctx) == 0:\n",
    "                    typs.append(classes[c].entity_types[i])\n",
    "            df.append((class_name, doc_id, ','.join(typs)))\n",
    "    return pd.DataFrame(df, columns=['relation', 'doc_id', 'missing'])\n",
    "df_miss = summarize_missing_candidates(cand_summary)\n",
    "df_miss.groupby(['relation', 'missing']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relation                     doc_id    \n",
       "SecretedCytokine             PMC3046151    13\n",
       "                             PMC2196041    11\n",
       "InducingTranscriptionFactor  PMC2587175    11\n",
       "                             PMC2646571     8\n",
       "                             PMC3173465     7\n",
       "                             PMC2783637     6\n",
       "SecretedCytokine             PMC2193209     5\n",
       "InducingCytokine             PMC2196041     5\n",
       "SecretedCytokine             PMC3650071     4\n",
       "InducingCytokine             PMC3173465     4\n",
       "InducingTranscriptionFactor  PMC3304099     4\n",
       "SecretedCytokine             PMC4385920     4\n",
       "InducingTranscriptionFactor  PMC4474185     3\n",
       "InducingCytokine             PMC2646571     3\n",
       "SecretedCytokine             PMC3204990     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find documents with most annotations unable to be matched and either improve tagging or change annotations\n",
    "df_miss.groupby(['relation', 'doc_id']).size().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels, load_matrix\n",
    "from snorkel.models import Candidate\n",
    "\n",
    "L_gold = {}\n",
    "for c in classes:\n",
    "    cids_query = get_cids_query(session, classes[c], split=1)\n",
    "    L_gold[c] = load_gold_labels(session, annotator_name=classes[c].field, split=1, cids_query=cids_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InducingCytokine (593, 1)\n",
      "SecretedCytokine (593, 1)\n",
      "InducingTranscriptionFactor (406, 1)\n"
     ]
    }
   ],
   "source": [
    "for c in L_gold:\n",
    "    print(c, L_gold[c].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate counts: InducingCytokine (split 0) -> 11836\n",
      "Candidate counts: InducingCytokine (split 1) -> 593\n",
      "Candidate counts: SecretedCytokine (split 0) -> 11836\n",
      "Candidate counts: SecretedCytokine (split 1) -> 593\n",
      "Candidate counts: InducingTranscriptionFactor (split 0) -> 8477\n",
      "Candidate counts: InducingTranscriptionFactor (split 1) -> 406\n"
     ]
    }
   ],
   "source": [
    "for c in classes.values():\n",
    "    for split in [0, 1]:\n",
    "        n = session.query(c.subclass).filter(c.subclass.split == split).count()\n",
    "        print('Candidate counts: {} (split {}) -> {}'.format(c.name, split, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  1\n",
       "0  0    416\n",
       "   1     65\n",
       "1  0    112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that inducing/secreted cytokine labels are mutally exclusive\n",
    "L_df = pd.DataFrame(np.hstack((\n",
    "    L_gold[classes.inducing_cytokine.name].toarray(), \n",
    "    L_gold[classes.secreted_cytokine.name].toarray()\n",
    ")))\n",
    "L_df.groupby([0, 1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InducingCytokine    593\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([\n",
    "    type(L_gold[classes.inducing_cytokine.name].get_candidate(session, i)).__name__ \n",
    "    for i in range(L_gold[classes.inducing_cytokine.name].shape[0])\n",
    "]).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
