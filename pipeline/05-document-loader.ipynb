{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Be careful not to import anything related to Snorkel here as it will crash pyarrow on staging step *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dotenv\n",
    "import shutil\n",
    "import glob\n",
    "import tqdm\n",
    "from tcre.env import *\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy.orm import sessionmaker\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69135 entries, 0 to 48693\n",
      "Data columns (total 18 columns):\n",
      "abstract          67211 non-null object\n",
      "arch_archive      48685 non-null object\n",
      "arch_id           48685 non-null object\n",
      "arch_name         48685 non-null object\n",
      "arch_path         48685 non-null object\n",
      "arch_venue        48685 non-null object\n",
      "body              58252 non-null object\n",
      "date_accepted     69135 non-null object\n",
      "date_pub          69135 non-null object\n",
      "date_received     69135 non-null object\n",
      "id_doi            65905 non-null object\n",
      "id_pmc            69135 non-null object\n",
      "id_pmid           68306 non-null object\n",
      "journal_ids       69135 non-null object\n",
      "journal_titles    69135 non-null object\n",
      "src               69135 non-null object\n",
      "text              20450 non-null object\n",
      "title             69133 non-null object\n",
      "dtypes: object(18)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_parquet(osp.join(IMPORT_DATA_DIR_02, 'corpus_01.parquet')).assign(src='entrez'),\n",
    "    pd.read_parquet(osp.join(IMPORT_DATA_DIR_03, 'corpus_03.parquet')).assign(src='pmcoa')\n",
    "], sort=True)\n",
    "assert df['id_pmc'].notnull().all()\n",
    "df = df.drop_duplicates(subset=['src', 'id_pmc'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entrez</th>\n",
       "      <th>pmcoa</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entrez  pmcoa  count\n",
       "0       0      1  43824\n",
       "1       1      0  15589\n",
       "2       1      1   4861"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show document intersection\n",
    "cts = df.assign(ind=1).pivot(index='id_pmc', columns='src', values='ind').fillna(0).astype(int)\n",
    "cts.groupby(['entrez', 'pmcoa']).size().rename('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    59413\n",
       "True      4861\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cts > 0).all(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_ids = cts[(cts > 0).all(axis=1)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64274 entries, 0 to 48693\n",
      "Data columns (total 18 columns):\n",
      "abstract          62360 non-null object\n",
      "arch_archive      43824 non-null object\n",
      "arch_id           43824 non-null object\n",
      "arch_name         43824 non-null object\n",
      "arch_path         43824 non-null object\n",
      "arch_venue        43824 non-null object\n",
      "body              53411 non-null object\n",
      "date_accepted     64274 non-null object\n",
      "date_pub          64274 non-null object\n",
      "date_received     64274 non-null object\n",
      "id_doi            61191 non-null object\n",
      "id_pmc            64274 non-null object\n",
      "id_pmid           63447 non-null object\n",
      "journal_ids       64274 non-null object\n",
      "journal_titles    64274 non-null object\n",
      "src               64274 non-null object\n",
      "text              20450 non-null object\n",
      "title             64272 non-null object\n",
      "dtypes: object(18)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Prefer entrez doc for duplicates (make docs unique)\n",
    "dff = df[(df['src'] == 'entrez') | ~df['id_pmc'].isin(dupe_ids)]\n",
    "assert dff['id_pmc'].is_unique\n",
    "dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src\n",
       "entrez    2635\n",
       "pmcoa     1886\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REMOVE: This will temporarily filter to only annotated documents and a small sample of all others\n",
    "# See: misc/id-set-generator.ipynb\n",
    "dfid = pd.read_csv(osp.join(DATA_DIR, 'idgroups', 'idgrp_small.csv'))\n",
    "is_annotated = ('PMC' + dff['id_pmc']).isin(dfid['id'].values)\n",
    "dff = pd.concat([\n",
    "    dff[is_annotated],\n",
    "    dff[~is_annotated].groupby('src', group_keys=False).apply(lambda g: g.sample(n=1000, random_state=TCRE_SEED))\n",
    "])\n",
    "dff.groupby('src').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['entrez', 'pmcoa'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['src'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 13.44it/s]\n"
     ]
    }
   ],
   "source": [
    "def stage_docs(df, batch_size=500, staging_dir='/tmp/corpus_staging'):\n",
    "    if osp.exists(staging_dir):\n",
    "        shutil.rmtree(staging_dir)\n",
    "    os.makedirs(staging_dir)\n",
    "\n",
    "    n_batches = len(df) // batch_size\n",
    "    batches = np.array_split(np.arange(len(df)), n_batches)\n",
    "    for i, batch in tqdm.tqdm(enumerate(batches), total=len(batches)):\n",
    "        path = osp.join(staging_dir, 'B{:05d}.feather'.format(i))\n",
    "        df.iloc[batch].reset_index(drop=True).to_feather(path)\n",
    "\n",
    "#stage_docs(dff[dff['src'] == 'entrez'])\n",
    "stage_docs(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Jobs To Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.models import Document, Sentence, Candidate\n",
    "from dask.distributed import Client, progress\n",
    "from tcre import processing\n",
    "from tcre import supervision\n",
    "import dask\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_jobs(staging_dir='/tmp/corpus_staging'):\n",
    "    jobs = []\n",
    "    for f in os.listdir(staging_dir):\n",
    "        i = int(f.split('.')[0][1:])\n",
    "        jobs.append((i, osp.join(staging_dir, f)))\n",
    "    return sorted(jobs)\n",
    "jobs = get_jobs()\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs = [jobs[i] for i in [  \n",
    "#     0,   1,   2,   3,   4,   5,   6,   8,   9,  11,  12,  13,  14,\n",
    "# ]]\n",
    "# len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Existing Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs before = 0 after = 0\n"
     ]
    }
   ],
   "source": [
    "def get_doc_ct():\n",
    "    session = SnorkelSession()\n",
    "    ct = session.query(Document).count()\n",
    "    session.close()\n",
    "    return ct\n",
    "    \n",
    "def clear_documents():\n",
    "    session = SnorkelSession()\n",
    "    parser = CorpusParser(parser=lambda v: None)\n",
    "    parser.clear(session)\n",
    "    session.commit()\n",
    "    session.close()\n",
    "    \n",
    "n = get_doc_ct()\n",
    "clear_documents()\n",
    "print('Num docs before =', n, 'after =', get_doc_ct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:34689\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:33015'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:46731'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:37205'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:41233'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:36377'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:44125'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:38563'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:35957'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:46483'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:40481'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:33425'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:39693'\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:33607\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:33607\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:37493\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:44587\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:33471\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:46221\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:35959\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:39595\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:46619\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:38661\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:42869\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:33911\n",
      "distributed.scheduler - INFO - Register tcp://172.17.0.2:43495\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:37493\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:44587\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:33471\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:46221\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:35959\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:39595\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:46619\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:38661\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:42869\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:33911\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://172.17.0.2:43495\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:36377'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:44125'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:39693'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:38563'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:33425'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:35957'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:46731'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:37205'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:40481'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:33015'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:41233'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:46483'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:33015'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:46731'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:37205'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:41233'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:36377'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:44125'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:38563'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:35957'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:46483'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:40481'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:33425'\n",
      "distributed.nanny - INFO -         Start Nanny at: 'tcp://172.17.0.2:39693'\n",
      "distributed.scheduler - INFO - Receive client connection: Client-2771cac2-b3b7-11e9-8a22-0242ac110002\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34689\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>3.07 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:34689' processes=12 cores=12>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(\n",
    "    threads_per_worker=1, n_workers=12, processes=True, \n",
    "    memory_limit='256GB', direct_to_workers=True, \n",
    "    silence_logs=logging.INFO\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(job):\n",
    "    import logging\n",
    "    logging.basicConfig()\n",
    "    batch_id, batch_file = job\n",
    "    logging.info('Processing job %s (%s)', batch_id, batch_file)\n",
    "    loader = processing.DocLoader(batch_file)\n",
    "    loader.run(limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55184e7b231e4863afc268dc09dab560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time estimates:\n",
    "# docs=20450 -> time=2hr 22min\n",
    "futures = client.map(process, jobs)\n",
    "dask.distributed.progress(futures, notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dask.distributed.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([f.status == 'finished' for f in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([f.status == 'finished' for f in futures]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere([f.status != 'finished' for f in futures]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.6/site-packages/distributed/client.py:1338: UserWarning: Shutdown is deprecated.  Please use close instead\n",
      "  warnings.warn(\"Shutdown is deprecated.  Please use close instead\")\n",
      "distributed.scheduler - INFO - Scheduler closing...\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:44587\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:44587\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:33607\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:33607\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:33471\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:33471\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:46221\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:46221\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:39595\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:39595\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:46619\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:46619\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:38661\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:38661\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:43495\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:43495\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:37493\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:37493\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:33911\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:33911\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:42869\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:42869\n",
      "distributed.scheduler - INFO - Remove worker tcp://172.17.0.2:35959\n",
      "distributed.core - INFO - Removing comms to tcp://172.17.0.2:35959\n",
      "distributed.scheduler - INFO - Lost all workers\n",
      "distributed.scheduler - INFO - Scheduler closing all comms\n",
      "distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:40481'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:46731'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:44125'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:33425'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:39693'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:38563'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:46483'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:37205'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:36377'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:33015'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:41233'\n",
      "distributed.nanny - INFO - Closing Nanny at 'tcp://172.17.0.2:35957'\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4521"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = SnorkelSession()\n",
    "session.query(Document).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
