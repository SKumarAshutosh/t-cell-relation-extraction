{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env scibert\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import torch\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly import graph_objs as go\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "tags_path = '/Users/eczech/data/research/hammer/nlp/20190311-pubmed-tcell-relation/articles/corpus/corpus_01/tags.csv'\n",
    "model_path = '/Users/eczech/tmp/scibert/scibert_scivocab_uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4007030 entries, 0 to 4007029\n",
      "Data columns (total 10 columns):\n",
      "id            object\n",
      "type          object\n",
      "ent_id        object\n",
      "ent_lbl       object\n",
      "ent_prefid    object\n",
      "start_chr     int64\n",
      "end_chr       int64\n",
      "start_wrd     int64\n",
      "end_wrd       int64\n",
      "text          object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 305.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(tags_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(model_path)\n",
    "model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# # Tokenized input\n",
    "# text = \"[CLS] Th17 differentiation is induced by IL-6. [SEP]\"\n",
    "# tokenized_text = tokenizer.tokenize(text)\n",
    "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# segments_ids = [1 for i in range(len(tokenized_text))]\n",
    "# tokens_tensor = torch.tensor([indexed_tokens])\n",
    "# segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtoken_embeddings(model, sentence):\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1 for i in range(len(tokenized_text))]\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "    token_embeddings = torch.squeeze(torch.sum(torch.stack(encoded_layers)[-4:], 0))\n",
    "    return tokenized_text, token_embeddings\n",
    "\n",
    "def get_word_embedding(sentence, token_embeddings, word):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cd',\n",
       " '##4',\n",
       " '+',\n",
       " 'cd',\n",
       " '##45',\n",
       " '##ra',\n",
       " '+',\n",
       " 'cd',\n",
       " '##45',\n",
       " '##ro',\n",
       " '##−',\n",
       " '##cd',\n",
       " '##62',\n",
       " '##l',\n",
       " '+',\n",
       " 'ccr',\n",
       " '##7',\n",
       " '+',\n",
       " 'cd',\n",
       " '##127',\n",
       " '+',\n",
       " 'cd',\n",
       " '##27',\n",
       " '+',\n",
       " 'cd',\n",
       " '##28',\n",
       " '+',\n",
       " 'cd',\n",
       " '##95',\n",
       " '+',\n",
       " 'cd',\n",
       " '##122',\n",
       " '+',\n",
       " 't',\n",
       " 'cells']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('CD4+CD45RA+CD45RO−CD62L+CCR7+CD127+CD27+CD28+CD95+CD122+ T cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[CLS] Furthermore, Th2 cells involved in allergic airway disease models express CCR4, and CCR4+ T cells from asthmatic patients are a predominant source of Th2 cytokines [SEP]'\n",
    "tokenized_text, token_embeddings = get_token_embeddings(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'furthermore',\n",
       " ',',\n",
       " 'th',\n",
       " '##2',\n",
       " 'cells',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'allergic',\n",
       " 'airway',\n",
       " 'disease',\n",
       " 'models',\n",
       " 'express',\n",
       " 'ccr',\n",
       " '##4',\n",
       " ',',\n",
       " 'and',\n",
       " 'ccr',\n",
       " '##4',\n",
       " '+',\n",
       " 't',\n",
       " 'cells',\n",
       " 'from',\n",
       " 'asthma',\n",
       " '##tic',\n",
       " 'patients',\n",
       " 'are',\n",
       " 'a',\n",
       " 'predominant',\n",
       " 'source',\n",
       " 'of',\n",
       " 'th',\n",
       " '##2',\n",
       " 'cytokines',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "# dimensions of `encoded_layers`\n",
    "# The layer number (12 layers)\n",
    "# The batch number (1 sentence)\n",
    "# The word / token number (22 tokens in our sentence)\n",
    "# The hidden unit / feature number (768 features)\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.squeeze(torch.sum(torch.stack(encoded_layers)[-4:], 0))\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
