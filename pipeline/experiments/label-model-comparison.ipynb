{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "from tcre.env import *\n",
    "from tcre.supervision import *\n",
    "from tcre.modeling import utils\n",
    "%matplotlib inline\n",
    "session = SnorkelSession()\n",
    "classes = get_candidate_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.models import Candidate, GoldLabel\n",
    "candidate_class = classes.inducing_cytokine\n",
    "cands = session.query(candidate_class.subclass)\\\n",
    "    .filter(candidate_class.subclass.split == SPLIT_DEV).all()\n",
    "len(cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30167</td>\n",
       "      <td>1</td>\n",
       "      <td>[[ IL-12 ]] induces not only Ifng expression1 but also T - bet ,   which promotes the survival and proliferation of differentiating &lt;&lt; TH1 &gt;&gt; cells .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30168</td>\n",
       "      <td>0</td>\n",
       "      <td>IL-12 induces not only [[ Ifng ]] expression1 but also T - bet ,   which promotes the survival and proliferation of differentiating &lt;&lt; TH1 &gt;&gt; cells .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30169</td>\n",
       "      <td>1</td>\n",
       "      <td>In mice , [[ TGFβ ]] together with IL6 can activate antigen - responsive naïve CD4 + T cells to develop into &lt;&lt; Th17 &gt;&gt; cells [ 39 ] .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30170</td>\n",
       "      <td>1</td>\n",
       "      <td>In mice , TGFβ together with [[ IL6 ]] can activate antigen - responsive naïve CD4 + T cells to develop into &lt;&lt; Th17 &gt;&gt; cells [ 39 ] .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30171</td>\n",
       "      <td>0</td>\n",
       "      <td>Several findings suggest that during the initiation of a &lt;&lt; Th1 &gt;&gt; response , [[ IL-12 ]] is produced particularly by macrophages in response to certain microbial antigens , while NK cells are the main source of IFN-γ in response to IL-12 ( 7 , 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cid  label  \\\n",
       "0  30167      1   \n",
       "1  30168      0   \n",
       "2  30169      1   \n",
       "3  30170      1   \n",
       "4  30171      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                        text  \n",
       "0                                                                                                   [[ IL-12 ]] induces not only Ifng expression1 but also T - bet ,   which promotes the survival and proliferation of differentiating << TH1 >> cells .     \n",
       "1                                                                                                   IL-12 induces not only [[ Ifng ]] expression1 but also T - bet ,   which promotes the survival and proliferation of differentiating << TH1 >> cells .     \n",
       "2                                                                                                                     In mice , [[ TGFβ ]] together with IL6 can activate antigen - responsive naïve CD4 + T cells to develop into << Th17 >> cells [ 39 ] .  \n",
       "3                                                                                                                     In mice , TGFβ together with [[ IL6 ]] can activate antigen - responsive naïve CD4 + T cells to develop into << Th17 >> cells [ 39 ] .  \n",
       "4  Several findings suggest that during the initiation of a << Th1 >> response , [[ IL-12 ]] is produced particularly by macrophages in response to certain microbial antigens , while NK cells are the main source of IFN-γ in response to IL-12 ( 7 , 1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 250)\n",
    "df = utils.get_candidate_df(cands, entity_markers=['[[', ']]', '<<', '>>'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'label']].to_csv('/tmp/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data as txd\n",
    "TEXT = txd.Field(lower=True)\n",
    "LABEL = txd.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lab/data/word2vec/PubMed-and-PMC-w2v.bin'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2V_MODEL_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "vectors = Vectors(name=W2V_MODEL_01, cache='/lab/data/word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4087443"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(featurizer.model.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4087446"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featurizer.model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.model.word(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.model.ix('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['</s>', 'the', ','], dtype='<U78')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.model.vocab[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import defaultdict, Counter\n",
    "    \n",
    "class W2VVocab(Vocab):\n",
    "    \n",
    "    def __init__(self, model, specials=['<pad>'], unk_init=np.zeros):\n",
    "        super().__init__(Counter())\n",
    "        self.itos = specials + list(model.vocab)\n",
    "        \n",
    "        unk_index = model.ix('UNK')\n",
    "        def get_unk_index():\n",
    "            return unk_index\n",
    "        self.stoi = defaultdict(get_unk_index)\n",
    "        self.stoi.update({w: i for i, w in enumerate(self.itos)})\n",
    "        self.vectors = torch.cat([\n",
    "            torch.FloatTensor(np.zeros((len(specials), model.vectors.shape[1]))),\n",
    "            torch.FloatTensor(model.vectors)\n",
    "        ], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab = W2VVocab(featurizer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = TEXT.vocab\n",
    "# self.embed = nn.Embedding(len(vocab), emb_dim)\n",
    "# self.embed.weight.data.copy_(vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = txd.TabularDataset('/tmp/data.csv'\n",
    "                         \n",
    "path='data/pos/pos_wsj_train.tsv', format='tsv',\n",
    "fields=[('text', data.Field()),\n",
    "        ('labels', data.Field())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcre.modeling import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tcre.modeling.features' from '/lab/repos/t-cell-relation-extraction/src/tcre/modeling/features.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = features.get_spacy_w2v_featurizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(df, featurizer):\n",
    "    X_train, Y_train = [], []\n",
    "    for i, r in df.iterrows():\n",
    "        indices, tokens = featurizer.indices(r['text'])\n",
    "        X_train.append(indices)\n",
    "        Y_train.append(r['label'])\n",
    "        assert r['label'] in [0, 1]\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = get_training_data(df, featurizer)\n",
    "idx_train, idx_test = train_test_split(np.arange(len(X)), test_size=.3, stratify=Y)\n",
    "X_train, Y_train = X[idx_train], Y[idx_train]\n",
    "X_test, Y_test = X[idx_test], Y[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tcre.modeling.models' from '/lab/repos/t-cell-relation-extraction/src/tcre/modeling/models.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcre.modeling import models\n",
    "#lstm = models.W2VLSTM(featurizer).build(hidden_dim=50, lr=.01, dropout=0) # min loss ~.11 at 50 epochs\n",
    "lstm = models.W2VLSTM(featurizer).build(hidden_dim=250, lr=.01, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W2VLSTM] Training model\n",
      "[W2VLSTM] n_train=471  #epochs=25  batch size=32\n",
      "[W2VLSTM] Epoch 1 (4.56s)\tAverage loss=0.648659\n",
      "[W2VLSTM] Epoch 2 (9.27s)\tAverage loss=0.492220\n",
      "[W2VLSTM] Epoch 3 (13.71s)\tAverage loss=0.482761\n",
      "[W2VLSTM] Epoch 4 (18.41s)\tAverage loss=0.460722\n",
      "[W2VLSTM] Epoch 5 (22.99s)\tAverage loss=0.441662\n",
      "[W2VLSTM] Epoch 6 (27.72s)\tAverage loss=0.433644\n",
      "[W2VLSTM] Epoch 7 (32.41s)\tAverage loss=0.435663\n",
      "[W2VLSTM] Epoch 8 (37.00s)\tAverage loss=0.543179\n",
      "[W2VLSTM] Epoch 9 (41.68s)\tAverage loss=0.484761\n",
      "[W2VLSTM] Epoch 10 (46.18s)\tAverage loss=0.495525\n",
      "[W2VLSTM] Epoch 11 (50.72s)\tAverage loss=0.469161\n",
      "[W2VLSTM] Epoch 12 (55.38s)\tAverage loss=0.451379\n",
      "[W2VLSTM] Epoch 13 (60.04s)\tAverage loss=0.436876\n",
      "[W2VLSTM] Epoch 14 (64.75s)\tAverage loss=0.412195\n",
      "[W2VLSTM] Epoch 15 (69.38s)\tAverage loss=0.404069\n",
      "[W2VLSTM] Epoch 16 (73.91s)\tAverage loss=0.403772\n",
      "[W2VLSTM] Epoch 17 (78.61s)\tAverage loss=0.397979\n",
      "[W2VLSTM] Epoch 18 (83.22s)\tAverage loss=0.393517\n",
      "[W2VLSTM] Epoch 19 (87.89s)\tAverage loss=0.385175\n",
      "[W2VLSTM] Epoch 20 (92.65s)\tAverage loss=0.379940\n",
      "[W2VLSTM] Epoch 21 (97.43s)\tAverage loss=0.374547\n",
      "[W2VLSTM] Epoch 22 (102.13s)\tAverage loss=0.379653\n",
      "[W2VLSTM] Epoch 23 (106.80s)\tAverage loss=0.359426\n",
      "[W2VLSTM] Epoch 24 (111.42s)\tAverage loss=0.331231\n",
      "[W2VLSTM] Epoch 25 (116.03s)\tAverage loss=0.331445\n",
      "[W2VLSTM] Training done (116.03s)\n"
     ]
    }
   ],
   "source": [
    "lstm.train(X_train, Y_train, n_epochs=25, batch_size=32, seed=1, dev_ckpt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
